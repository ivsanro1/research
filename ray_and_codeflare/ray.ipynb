{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af01ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Override/set credentials in env var\n",
    "os.environ['CWD'] = str(Path(os.getcwd()).parent)\n",
    "\n",
    "# Base paths\n",
    "cwd = Path(os.environ['CWD'])\n",
    "dir_data = cwd / 'data'\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef47448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"ray[serve]==1.11.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bb0b537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 12:17:59,537\tINFO services.py:1414 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://172.18.0.2:8265\u001b[39m\u001b[22m\n",
      "2022-04-05 12:17:59,540\tWARNING services.py:1919 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=1.71gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "\u001b[2m\u001b[36m(ServeController pid=45678)\u001b[0m 2022-04-05 12:18:01,265\tINFO checkpoint_path.py:16 -- Using RayInternalKVStore for controller checkpoint and recovery.\n",
      "\u001b[2m\u001b[36m(ServeController pid=45678)\u001b[0m 2022-04-05 12:18:01,373\tINFO http_state.py:101 -- Starting HTTP proxy with name 'SERVE_CONTROLLER_ACTOR:fULZbQ:SERVE_PROXY_ACTOR-node:172.18.0.2-0' on node 'node:172.18.0.2-0' listening on '127.0.0.1:8000'\n",
      "2022-04-05 12:18:01,632\tINFO api.py:521 -- Started Serve instance in namespace '19b0d345-667c-4a5e-9f6f-f039ee8d8d1b'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.serve.api.Client at 0x7f46e81f3d50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=45681)\u001b[0m INFO:     Started server process [45681]\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray import serve\n",
    "ray.init(dashboard_host=\"0.0.0.0\")\n",
    "serve.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d3702b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Train model.\n",
    "iris_dataset = load_iris()\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(iris_dataset[\"data\"], iris_dataset[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c573734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "# @serve.deployment(route_prefix=\"/iris\")\n",
    "class BoostingModel:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.label_list = iris_dataset[\"target_names\"].tolist()\n",
    "        self.n_calls = 0\n",
    "\n",
    "    async def __call__(self, request):\n",
    "        if type(request) == dict: # For local pred\n",
    "            payload = request[\"vector\"]\n",
    "        else: # For HTTP pred\n",
    "            payload = (await request.json())[\"vector\"]\n",
    "        print(f\"Received http request with data {payload}\")\n",
    "        sleep(6)\n",
    "        prediction = self.model.predict([payload])[0]\n",
    "        human_name = self.label_list[prediction]\n",
    "        self.n_calls += 1\n",
    "        return {\n",
    "            \"result\": human_name,\n",
    "            \"n_calls\": self.n_calls\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3277b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try actor locally\n",
    "# Instantiate object\n",
    "boosting_model = BoostingModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "883fe703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received http request with data [1.2, 1.0, 1.1, 0.9]\n"
     ]
    }
   ],
   "source": [
    "# Make pred\n",
    "d_ret = await boosting_model({\"vector\": [1.2, 1.0, 1.1, 0.9]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ab69b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': 'versicolor'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48104197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 12:26:10,299\tINFO api.py:262 -- Updating deployment 'BoostingModel'. component=serve deployment=BoostingModel\n",
      "\u001b[2m\u001b[36m(ServeController pid=45678)\u001b[0m 2022-04-05 12:26:10,313\tINFO deployment_state.py:882 -- Stopping 1 replicas of deployment 'BoostingModel' with outdated versions. component=serve deployment=BoostingModel\n",
      "\u001b[2m\u001b[36m(ServeController pid=45678)\u001b[0m 2022-04-05 12:26:12,525\tINFO deployment_state.py:920 -- Adding 1 replicas to deployment 'BoostingModel'. component=serve deployment=BoostingModel\n",
      "2022-04-05 12:26:13,818\tINFO api.py:275 -- Deployment 'BoostingModel' is ready at `http://127.0.0.1:8000/iris`. component=serve deployment=BoostingModel\n"
     ]
    }
   ],
   "source": [
    "# Deploy the same actor\n",
    "serve.deployment(route_prefix=\"/iris\")(BoostingModel).deploy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec0428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c00086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50f12902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(BoostingModel pid=49188)\u001b[0m Received http request with data [1.2, 1.0, 0, 0.9]\n",
      "\u001b[2m\u001b[36m(BoostingModel pid=49223)\u001b[0m Received http request with data [1.2, 1.0, 1.1, 0.9]\n",
      "{\n",
      "  \"result\": \"versicolor\",\n",
      "  \"n_calls\": 4\n",
      "}\n",
      "\u001b[2m\u001b[36m(BoostingModel pid=49188)\u001b[0m Received http request with data [1.2, 1.0, 1.1, 0.9]\n"
     ]
    }
   ],
   "source": [
    "# Query it!\n",
    "import requests\n",
    "sample_request_input = {\"vector\": [1.2, 1.0, 0, 0.9]}\n",
    "response = requests.get(\n",
    "    \"http://localhost:8000/iris\", json=sample_request_input)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e65d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query it!\n",
    "import requests\n",
    "sample_request_input = {\"vector\": [1.2, 1.0, 1.1, 0.9]}\n",
    "response = requests.get(\n",
    "    \"http://localhost:8000/iris\", json=sample_request_input)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5756fcd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54b06c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BoostingModel': Deployment(name=BoostingModel,version=None,route_prefix=/iris)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serve.list_deployments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25bc1705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 13:06:30,311\tINFO api.py:262 -- Updating deployment 'BoostingModel'. component=serve deployment=BoostingModel\n",
      "\u001b[2m\u001b[36m(ServeController pid=45678)\u001b[0m 2022-04-05 13:06:30,331\tINFO deployment_state.py:920 -- Adding 1 replicas to deployment 'BoostingModel'. component=serve deployment=BoostingModel\n",
      "\u001b[2m\u001b[36m(ServeController pid=45678)\u001b[0m 2022-04-05 13:06:31,616\tINFO deployment_state.py:882 -- Stopping 1 replicas of deployment 'BoostingModel' with outdated versions. component=serve deployment=BoostingModel\n",
      "\u001b[2m\u001b[36m(ServeController pid=45678)\u001b[0m 2022-04-05 13:06:33,742\tINFO deployment_state.py:920 -- Adding 1 replicas to deployment 'BoostingModel'. component=serve deployment=BoostingModel\n",
      "2022-04-05 13:06:34,911\tINFO api.py:275 -- Deployment 'BoostingModel' is ready at `http://127.0.0.1:8000/iris`. component=serve deployment=BoostingModel\n"
     ]
    }
   ],
   "source": [
    "serve.get_deployment('BoostingModel').options(num_replicas=2).deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5a204b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13c3e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aa1ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
